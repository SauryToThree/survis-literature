define({ entries : {
    "10.1145/2370816.2370865": {
        "abstract": "Accurate simulation is essential for the proper design and evaluation of any computing platform. Upon the current move toward the CPU-GPU heterogeneous computing era, researchers need a simulation framework that can model both kinds of computing devices and their interaction. In this paper, we present Multi2Sim, an open-source, modular, and fully configurable toolset that enables ISA-level simulation of an x86 CPU and an AMD Evergreen GPU. Focusing on a model of the AMD Radeon 5870 GPU, we address program emulation correctness, as well as architectural simulation accuracy, using AMD's OpenCL benchmark suite. Simulation capabilities are demonstrated with a preliminary architectural exploration study, and workload characterization examples. The project source code, benchmark packages, and a detailed user's guide are publicly available at www.multi2sim.org.",
        "address": "New York, NY, USA",
        "author": "Ubal, Rafael and Jang, Byunghyun and Mistry, Perhaad and Schaa, Dana and Kaeli, David",
        "booktitle": "Proceedings of the 21st International Conference on Parallel Architectures and Compilation Techniques",
        "doi": "10.1145/2370816.2370865",
        "isbn": "9781450311823",
        "keywords": "CPU-GPU, heterogeneous computing, multi2sim, simulation",
        "location": "Minneapolis, Minnesota, USA",
        "numpages": "10",
        "pages": "335\u2013344",
        "publisher": "Association for Computing Machinery",
        "series": "PACT '12",
        "title": "Multi2Sim: a simulation framework for CPU-GPU computing",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/2370816.2370865",
        "year": "2012"
    },
    "10.1145/279361.279399": {
        "abstract": "Much of the improvement in computer performance over the last twenty years has come from faster transistors and architectural advances that increase parallelism. Historically, parallelism has been exploited either at the instruction level with a grain-size of a single instruction or by partitioning applications into coarse threads with grain-sizes of thousands of instructions. Fine-grain threads fill the parallelism gap between these extremes by enabling tasks with run lengths as small as 20 cycles. As this fine-grain parallelism is orthogonal to ILP and coarse threads, it complements both methods and provides an opportunity for greater speedup. This paper describes the efficient communication and synchronization mechanisms implemented in the Multi-ALU Processor (MAP) chip, including a thread creation instruction, register communication, and a hardware barrier. These register-based mechanisms provide 10 times faster communication and 60 times faster synchronization than mechanisms that operate via a shared on chip cache. With a three-processor implementation of the MAP, fine-grain speedups of 1.2-2.1 are demonstrated on a suite of applications.",
        "address": "New York, NY, USA",
        "author": "Keckler, Stephen W. and Dally, William J. and Maskit, Daniel and Carter, Nicholas P. and Chang, Andrew and Lee, Whay S.",
        "doi": "10.1145/279361.279399",
        "issn": "0163-5964",
        "issue_date": "June 1998",
        "journal": "SIGARCH Comput. Archit. News",
        "month": "apr,",
        "number": "3",
        "numpages": "12",
        "pages": "306\u2013317",
        "publisher": "Association for Computing Machinery",
        "title": "Exploiting fine-grain thread level parallelism on the MIT multi-ALU processor",
        "type": "article",
        "url": "https://doi.org/10.1145/279361.279399",
        "volume": "26",
        "year": "1998"
    },
    "10.1145/2962131": {
        "abstract": "Modern graphics processing units (GPUs) have complex architectures that admit exceptional performance and energy efficiency for high-throughput applications. Although GPUs consume large amounts of power, their use for high-throughput applications facilitate state-of-the-art energy efficiency and performance. Consequently, continued development relies on understanding their power consumption. This work is a survey of GPU power modeling and profiling methods with increased detail on noteworthy efforts. As direct measurement of GPU power is necessary for model evaluation and parameter initiation, internal and external power sensors are discussed. Hardware counters, which are low-level tallies of hardware events, share strong correlation to power use and performance. Statistical correlation between power and performance counters has yielded worthwhile GPU power models, yet the complexity inherent to GPU architectures presents new hurdles for power modeling. Developments and challenges of counter-based GPU power modeling are discussed. Often building on the counter-based models, research efforts for GPU power simulation, which make power predictions from input code and hardware knowledge, provide opportunities for optimization in programming or architectural design. Noteworthy strides in power simulations for GPUs are included along with their performance or functional simulator counterparts when appropriate. Last, possible directions for future research are discussed.",
        "address": "New York, NY, USA",
        "articleno": "41",
        "author": "Bridges, Robert A. and Imam, Neena and Mintz, Tiffany M.",
        "doi": "10.1145/2962131",
        "issn": "0360-0300",
        "issue_date": "September 2017",
        "journal": "ACM Comput. Surv.",
        "keywords": "GPGPU, GPU, power model, power profile, simulation",
        "month": "sep,",
        "number": "3",
        "numpages": "27",
        "publisher": "Association for Computing Machinery",
        "title": "Understanding GPU Power: A Survey of Profiling, Modeling, and Simulation Methods",
        "type": "article",
        "url": "https://doi.org/10.1145/2962131",
        "volume": "49",
        "year": "2016"
    },
    "10.1145/3168831": {
        "abstract": "General-purpose GPUs have been widely utilized to accelerate parallel applications. Given a relatively complex programming model and fast architecture evolution, producing efficient GPU code is nontrivial. A variety of simulation and profiling tools have been developed to aid GPU application optimization and architecture design. However, existing tools are either limited by insufficient insights or lacking in support across different GPU architectures, runtime and driver versions. This paper presents CUDAAdvisor, a profiling framework to guide code optimization in modern NVIDIA GPUs. CUDAAdvisor performs various fine-grained analyses based on the profiling results from GPU kernels, such as memory-level analysis (e.g., reuse distance and memory divergence), control flow analysis (e.g., branch divergence) and code-/data-centric debugging. Unlike prior tools, CUDAAdvisor supports GPU profiling across different CUDA versions and architectures, including CUDA 8.0 and Pascal architecture. We demonstrate several case studies that derive significant insights to guide GPU code optimization for performance improvement.",
        "address": "New York, NY, USA",
        "author": "Shen, Du and Song, Shuaiwen Leon and Li, Ang and Liu, Xu",
        "booktitle": "Proceedings of the 2018 International Symposium on Code Generation and Optimization",
        "doi": "10.1145/3168831",
        "isbn": "9781450356176",
        "keywords": "GPU, LLVM, Optimization, Profiling",
        "location": "Vienna, Austria",
        "numpages": "14",
        "pages": "214\u2013227",
        "publisher": "Association for Computing Machinery",
        "series": "CGO '18",
        "title": "CUDAAdvisor: LLVM-based runtime profiling for modern GPUs",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/3168831",
        "year": "2018"
    },
    "10.1145/3224430": {
        "abstract": "Contemporary Graphics Processing Units (GPUs) are used to accelerate highly parallel compute workloads. For the last decade, researchers in academia and industry have used cycle-level GPU architecture simulators to evaluate future designs. This paper performs an in-depth analysis of commonly accepted GPU simulation methodology, examining the effect both the workload and the choice of instruction set architecture have on the accuracy of a widely-used simulation infrastructure, GPGPU-Sim. We analyze numerous aspects of the architecture, validating the simulation results against real hardware. Based on a characterized set of over 1700 GPU kernels, we demonstrate that while the relative accuracy of compute-intensive workloads is high, inaccuracies in modeling the memory system result in much higher error when memory performance is critical. We then perform a case study using a recently proposed GPU architecture modification, Cache-Conscious Wavefront Scheduling. The case study demonstrates that the cross-product of workload characteristics and instruction set architecture choice can affect the predicted efficacy of the technique.",
        "address": "New York, NY, USA",
        "articleno": "35",
        "author": "Jain, Akshay and Khairy, Mahmoud and Rogers, Timothy G.",
        "doi": "10.1145/3224430",
        "issue_date": "June 2018",
        "journal": "Proc. ACM Meas. Anal. Comput. Syst.",
        "keywords": "simulator, performance, modeling, gpgpu-sim, error, correlation",
        "month": "jun,",
        "number": "2",
        "numpages": "28",
        "publisher": "Association for Computing Machinery",
        "title": "A Quantitative Evaluation of Contemporary GPU Simulation Methodology",
        "type": "article",
        "url": "https://doi.org/10.1145/3224430",
        "volume": "2",
        "year": "2018"
    },
    "10.1145/3582016.3582024": {
        "abstract": "Graphics rendering remains one of the most compute intensive and memory bound applications of GPUs and has been driving their push for performance and energy efficiency since its inception. Early GPU architectures focused only on accelerating graphics rendering and implemented dedicated fixed- function rasterizer hardware to speed-up their rendering pipeline. As GPUs have become more programmable and ubiquitous in other application domains such as scientific computing, machine learning, graph analytics, and crypto-currency, generalizing GPU microarchitectures for area and power efficiency becomes necessary, especially for mobile and IoT devices. In this work, we present Skybox, a full-stack open-source GPU architecture with integrated software, compiler, hardware, and simulation environment, that enables end-to-end GPU research. Using Skybox, we explore the design space of software versus hardware graphics rendering and propose and hybrid micro-architecture that accelerates the state-of-the art Vulkan graphics API. Skybox also introduces novel compiler and system optimizations to support its unique RISC-V ISA baseline. We evaluated Skybox on high- end Altera and also Xilinx FPGAs. We were able to generate and execute a 32 cores (512 threads) Skybox graphics processor on Altera Stratix 10 FPGA, delivering a peak fill rate of 3.7 GPixels at 230 MHz. Skybox is the first open-source full-stack GPU software and hardware implementation that supports the Vulkan API.",
        "address": "New York, NY, USA",
        "author": "Tine, Blaise and Saxena, Varun and Srivatsan, Santosh and Simpson, Joshua R. and Alzammar, Fadi and Cooper, Liam and Kim, Hyesoon",
        "booktitle": "Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3",
        "doi": "10.1145/3582016.3582024",
        "isbn": "9781450399180",
        "keywords": "microarchitecture, hardware accelerator, graphics",
        "location": "Vancouver, BC, Canada",
        "numpages": "15",
        "pages": "616\u2013630",
        "publisher": "Association for Computing Machinery",
        "series": "ASPLOS 2023",
        "title": "Skybox: Open-Source Graphic Rendering on Programmable RISC-V GPUs",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/3582016.3582024",
        "year": "2023"
    },
    "5749714": {
        "author": "Fung, Wilson W. L. and Aamodt, Tor M.",
        "booktitle": "2011 IEEE 17th International Symposium on High Performance Computer Architecture",
        "doi": "10.1109/HPCA.2011.5749714",
        "keywords": "Instruction sets;Graphics processing unit;Compaction;Hardware;Kernel;Pipelines;Random access memory",
        "number": "",
        "pages": "25-36",
        "title": "Thread block compaction for efficient SIMT control flow",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2011"
    },
    "7069297": {
        "author": "Bertolli, Carlo and Antao, Samuel F. and Eichenberger, Alexandre E. and Sura, Kevin OBrien Zehra and Jacob, Arpith C. and Chen, Tong and Sallenave, Olivier",
        "booktitle": "2014 LLVM Compiler Infrastructure in HPC",
        "doi": "10.1109/LLVM-HPC.2014.10",
        "keywords": "Graphics processing units;Kernel;Parallel processing;Synchronization;Acceleration;Performance evaluation",
        "number": "",
        "pages": "12-21",
        "title": "Coordinating GPU Threads for OpenMP 4.0 in LLVM",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2014"
    },
    "9238604": {
        "author": "Elhelw, Amr S. and Pai, Sreepathi",
        "booktitle": "2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)",
        "doi": "10.1109/ISPASS48437.2020.00020",
        "keywords": "Instruments;Instruction sets;Semantics;Graphics processing units;Hardware;Software;Performance analysis;functional simulator;formal semantics;GPU;instrumentation",
        "number": "",
        "pages": "104-106",
        "title": "Horus: A Modular GPU Emulator Framework",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2020"
    },
    "NEURIPS2020_e4d78a6b": {
        "author": "Dalton, Steven and frosio, iuri",
        "booktitle": "Advances in Neural Information Processing Systems",
        "editor": "H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin",
        "pages": "19773--19782",
        "publisher": "Curran Associates, Inc.",
        "title": "Accelerating Reinforcement Learning through GPU Atari Emulation",
        "type": "inproceedings",
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/e4d78a6b4d93e1d79241f7b282fa3413-Paper.pdf",
        "volume": "33",
        "year": "2020"
    }
}});